{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Zoomcamp Session 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOXmisxItH2ae02PIpqYT8E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketsharma00411/ML-Zoomcamp/blob/main/Session%203/Session%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJkro_Frvzc8"
      },
      "source": [
        "## Session 3\n",
        "\n",
        "https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/03-classification/homework.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzHRzPbkv5Ez"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao0u8P2hvZGP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgXHafYJwDZy"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "In this homework, we will continue the New York City Airbnb Open Data. You can take it from\n",
        "[Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\n",
        "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\n",
        "if you don't want to sign up to Kaggle.\n",
        "\n",
        "We'll keep working with the `'price'` variable, and we'll transform it to a classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr3esq0Dv9ig",
        "outputId": "519d544d-1a71-4771-be76-bfb2bbc30228"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-24 20:38:14--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7077973 (6.8M) [text/plain]\n",
            "Saving to: ‘AB_NYC_2019.csv’\n",
            "\n",
            "\rAB_NYC_2019.csv       0%[                    ]       0  --.-KB/s               \rAB_NYC_2019.csv     100%[===================>]   6.75M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-09-24 20:38:14 (76.2 MB/s) - ‘AB_NYC_2019.csv’ saved [7077973/7077973]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ciSthWL_xEjr",
        "outputId": "f2ca4f41-b3bf-468c-cc55-0ef34c95bb8b"
      },
      "source": [
        "data = pd.read_csv('AB_NYC_2019.csv')\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>host_id</th>\n",
              "      <th>host_name</th>\n",
              "      <th>neighbourhood_group</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>room_type</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>last_review</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2539</td>\n",
              "      <td>Clean &amp; quiet apt home by the park</td>\n",
              "      <td>2787</td>\n",
              "      <td>John</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Kensington</td>\n",
              "      <td>40.64749</td>\n",
              "      <td>-73.97237</td>\n",
              "      <td>Private room</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2018-10-19</td>\n",
              "      <td>0.21</td>\n",
              "      <td>6</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2595</td>\n",
              "      <td>Skylit Midtown Castle</td>\n",
              "      <td>2845</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Midtown</td>\n",
              "      <td>40.75362</td>\n",
              "      <td>-73.98377</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>225</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>2019-05-21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3647</td>\n",
              "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
              "      <td>4632</td>\n",
              "      <td>Elisabeth</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Harlem</td>\n",
              "      <td>40.80902</td>\n",
              "      <td>-73.94190</td>\n",
              "      <td>Private room</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3831</td>\n",
              "      <td>Cozy Entire Floor of Brownstone</td>\n",
              "      <td>4869</td>\n",
              "      <td>LisaRoxanne</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Clinton Hill</td>\n",
              "      <td>40.68514</td>\n",
              "      <td>-73.95976</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>2019-07-05</td>\n",
              "      <td>4.64</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5022</td>\n",
              "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
              "      <td>7192</td>\n",
              "      <td>Laura</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>East Harlem</td>\n",
              "      <td>40.79851</td>\n",
              "      <td>-73.94399</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>2018-11-19</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ... availability_365\n",
              "0  2539  ...              365\n",
              "1  2595  ...              355\n",
              "2  3647  ...              365\n",
              "3  3831  ...              194\n",
              "4  5022  ...                0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_CkaF6BwOJN"
      },
      "source": [
        "### Features\n",
        "\n",
        "For the rest of the homework, you'll need to use the features from the previous homework with additional two `'neighbourhood_group'` and `'room_type'`. So the whole feature set will be set as follows:\n",
        "\n",
        "* `'neighbourhood_group'`,\n",
        "* `'room_type'`,\n",
        "* `'latitude'`,\n",
        "* `'longitude'`,\n",
        "* `'price'`,\n",
        "* `'minimum_nights'`,\n",
        "* `'number_of_reviews'`,\n",
        "* `'reviews_per_month'`,\n",
        "* `'calculated_host_listings_count'`,\n",
        "* `'availability_365'`\n",
        "\n",
        "Select only them and fill in the missing values with 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E9p7WnDwS5a"
      },
      "source": [
        "features = [            \n",
        "    'neighbourhood_group',\n",
        "    'room_type',\n",
        "    'latitude',\n",
        "    'longitude',\n",
        "    'price',\n",
        "    'minimum_nights',\n",
        "    'number_of_reviews',\n",
        "    'reviews_per_month',\n",
        "    'calculated_host_listings_count',\n",
        "    'availability_365'\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqrY4793xCY7"
      },
      "source": [
        "data = data[features].fillna(0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck_UfYXkwTXu"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "What is the most frequent observation (mode) for the column `'neighbourhood_group'`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3QBDhxvwWfC",
        "outputId": "0df1755b-32fe-45a4-edad-757404cf5e3b"
      },
      "source": [
        "data.neighbourhood_group.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Manhattan        21661\n",
              "Brooklyn         20104\n",
              "Queens            5666\n",
              "Bronx             1091\n",
              "Staten Island      373\n",
              "Name: neighbourhood_group, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTmtjAf9xnhw"
      },
      "source": [
        "The most frequent observation (mode) for the column `'neighbourhood_group'` is **Manhattan**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSkJcVFdwW2q"
      },
      "source": [
        "### Split the data\n",
        "\n",
        "* Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
        "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to 42.\n",
        "* Make sure that the target value ('price') is not in your dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0RZJvsmwZ-4"
      },
      "source": [
        "X_full_train, X_test, y_full_train, y_test = train_test_split(data.drop(['price'], axis=1), data['price'], test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_full_train, y_full_train, test_size=0.25, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjjzmWm9waNO"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "* Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your train dataset.\n",
        "   * In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
        "* What are the two features that have the biggest correlation in this dataset?\n",
        "\n",
        "Example of a correlation matrix for the car price dataset:\n",
        "\n",
        "<img src=\"https://github.com/alexeygrigorev/mlbookcamp-code/raw/master/course-zoomcamp/03-classification/images/correlation-matrix.png\" />"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "za_0HpZ7wdT1",
        "outputId": "1c78e99e-bffe-4ffb-d60f-b2252c3d1f3e"
      },
      "source": [
        "corr_mat = X_train.corr()\n",
        "corr_mat"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>latitude</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.080301</td>\n",
              "      <td>0.027441</td>\n",
              "      <td>-0.006246</td>\n",
              "      <td>-0.007159</td>\n",
              "      <td>0.019375</td>\n",
              "      <td>-0.005891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>longitude</th>\n",
              "      <td>0.080301</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.060660</td>\n",
              "      <td>0.055084</td>\n",
              "      <td>0.134642</td>\n",
              "      <td>-0.117041</td>\n",
              "      <td>0.083666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minimum_nights</th>\n",
              "      <td>0.027441</td>\n",
              "      <td>-0.060660</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.076020</td>\n",
              "      <td>-0.120703</td>\n",
              "      <td>0.118647</td>\n",
              "      <td>0.138901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_reviews</th>\n",
              "      <td>-0.006246</td>\n",
              "      <td>0.055084</td>\n",
              "      <td>-0.076020</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.590374</td>\n",
              "      <td>-0.073167</td>\n",
              "      <td>0.174477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviews_per_month</th>\n",
              "      <td>-0.007159</td>\n",
              "      <td>0.134642</td>\n",
              "      <td>-0.120703</td>\n",
              "      <td>0.590374</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.048767</td>\n",
              "      <td>0.165376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <td>0.019375</td>\n",
              "      <td>-0.117041</td>\n",
              "      <td>0.118647</td>\n",
              "      <td>-0.073167</td>\n",
              "      <td>-0.048767</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.225913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>availability_365</th>\n",
              "      <td>-0.005891</td>\n",
              "      <td>0.083666</td>\n",
              "      <td>0.138901</td>\n",
              "      <td>0.174477</td>\n",
              "      <td>0.165376</td>\n",
              "      <td>0.225913</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                latitude  ...  availability_365\n",
              "latitude                        1.000000  ...         -0.005891\n",
              "longitude                       0.080301  ...          0.083666\n",
              "minimum_nights                  0.027441  ...          0.138901\n",
              "number_of_reviews              -0.006246  ...          0.174477\n",
              "reviews_per_month              -0.007159  ...          0.165376\n",
              "calculated_host_listings_count  0.019375  ...          0.225913\n",
              "availability_365               -0.005891  ...          1.000000\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FCbM2kI0lQ4"
      },
      "source": [
        "`'number_of_reviews'` and `'reviews_per_month'` are the features with the biggest correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EwC17zOwdkW"
      },
      "source": [
        "### Make price binary\n",
        "\n",
        "* We need to turn the price variable from numeric into binary.\n",
        "* Let's create a variable `above_average` which is `1` if the price is above (or equal to) `152`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yJtUdj2whQi",
        "outputId": "d2b3f5d4-6962-44a7-8950-bf31526d0592"
      },
      "source": [
        "above_average = (y_train >= 152).astype(int)\n",
        "above_average"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13575    0\n",
              "48476    0\n",
              "44499    0\n",
              "17382    0\n",
              "14638    0\n",
              "        ..\n",
              "13198    0\n",
              "14583    0\n",
              "6168     1\n",
              "12248    0\n",
              "20523    0\n",
              "Name: price, Length: 29337, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjFld0OiwheM"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "* Calculate the mutual information score with the (binarized) price for the two categorical variables that we have. Use the training set only.\n",
        "* Which of these two variables has bigger score?\n",
        "* Round it to 2 decimal digits using `round(score, 2)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJRpN6JuwkhH",
        "outputId": "1237c3d9-cbf9-4c8e-8803-2586b5843a0d"
      },
      "source": [
        "round(mutual_info_score(above_average, X_train.neighbourhood_group), 2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-kHF84P4deO",
        "outputId": "fbc2ffbb-bb58-49cb-8b53-46ae298a15f0"
      },
      "source": [
        "round(mutual_info_score(above_average, X_train.room_type), 2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2esnukCs4rn2"
      },
      "source": [
        "`'room_type'` has higher mutual information score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1Ewa1nOwkwO"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "* Now let's train a logistic regression\n",
        "* Remember that we have two categorical variables in the data. Include them using one-hot encoding.\n",
        "* Fit the model on the training dataset.\n",
        "   * To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
        "   * `model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)`\n",
        "* Calculate the accuracy on the validation dataset and rount it to 2 decimal digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GW8KbM2wn2K"
      },
      "source": [
        "dv = DictVectorizer(sparse=False)\n",
        "\n",
        "train_dict = X_train.to_dict(orient='records')\n",
        "X_train_transformed = dv.fit_transform(train_dict)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmpSAnJW7AFl",
        "outputId": "1ebe8f14-8512-4908-cc82-b57ae8ec995a"
      },
      "source": [
        "model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n",
        "model.fit(X_train_transformed, above_average)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO2tQVsf7sRW"
      },
      "source": [
        "val_dict = X_val.to_dict(orient='records')\n",
        "X_val_transformed = dv.transform(val_dict)\n",
        "\n",
        "y_val_binary = (y_val >= 152).astype(int)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEFtpGTQ7k7s",
        "outputId": "3c6ad091-3fc0-4705-ebf4-117e9bd14358"
      },
      "source": [
        "round(model.score(X_val_transformed, y_val_binary), 2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.79"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZQw9m6-woDz"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "* We have 9 features: 7 numerical features and 2 categorical.\n",
        "* Let's find the least useful one using the *feature elimination* technique.\n",
        "* Train a model with all these features (using the same parameters as in Q4).\n",
        "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
        "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \n",
        "* Which of following feature has the smallest difference? \n",
        "   * `neighbourhood_group`\n",
        "   * `room_type` \n",
        "   * `number_of_reviews`\n",
        "   * `reviews_per_month`\n",
        "\n",
        "> **note**: the difference doesn't have to be positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3ay0rStwqHE",
        "outputId": "c75edab0-aef6-4929-8ad7-ea9793eeead7"
      },
      "source": [
        "dv = DictVectorizer(sparse=False)\n",
        "train_dict = X_train.to_dict(orient='records')\n",
        "X_train_transformed = dv.fit_transform(train_dict)\n",
        "\n",
        "val_dict = X_val.to_dict(orient='records')\n",
        "X_val_transformed_full = dv.transform(val_dict)\n",
        "y_val_binary = (y_val >= 152).astype(int)\n",
        "\n",
        "full_model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n",
        "full_model.fit(X_train_transformed, above_average)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNieF-g0eMcW",
        "outputId": "7e4d9589-a1f7-47b9-97fe-9d48684f514b"
      },
      "source": [
        "final_features = features.copy()\n",
        "final_features.pop(4)\n",
        "final_features"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neighbourhood_group',\n",
              " 'room_type',\n",
              " 'latitude',\n",
              " 'longitude',\n",
              " 'minimum_nights',\n",
              " 'number_of_reviews',\n",
              " 'reviews_per_month',\n",
              " 'calculated_host_listings_count',\n",
              " 'availability_365']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHbHmHhwc4kC",
        "outputId": "bc7c7382-cb38-4e29-fd50-59e4fd64d905"
      },
      "source": [
        "diffs = {}\n",
        "for feature in final_features:\n",
        "    dv = DictVectorizer(sparse=False)\n",
        "    train_dict = X_train.drop([feature], axis=1).to_dict(orient='records')\n",
        "    X_train_transformed = dv.fit_transform(train_dict)\n",
        "    \n",
        "    val_dict = X_val.drop([feature], axis=1).to_dict(orient='records')\n",
        "    X_val_transformed = dv.transform(val_dict)\n",
        "    # y_val_binary = (y_val >= 152).astype(int)\n",
        "\n",
        "    model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)\n",
        "    model.fit(X_train_transformed, above_average)\n",
        "\n",
        "    diffs[feature] = full_model.score(X_val_transformed_full, y_val_binary) - model.score(X_val_transformed, y_val_binary)\n",
        "\n",
        "diffs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'availability_365': 0.004908477349422236,\n",
              " 'calculated_host_listings_count': -0.0002045198895592737,\n",
              " 'latitude': 0.00010225994477963685,\n",
              " 'longitude': -0.00030677983433891054,\n",
              " 'minimum_nights': 0.0009203395030166206,\n",
              " 'neighbourhood_group': 0.03548420083853154,\n",
              " 'number_of_reviews': -0.0005112997238981842,\n",
              " 'reviews_per_month': 0.0014316392269148048,\n",
              " 'room_type': 0.06994580222926683}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVw_NF_YevKT",
        "outputId": "83f3d385-ef4b-428c-af3d-ee030cc4a707"
      },
      "source": [
        "min(diffs.values())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0005112997238981842"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8sR-xE2hRDD"
      },
      "source": [
        "`'number_of_reviews'` has the smallest difference and is the least useful feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV209g3owqY3"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "* For this question, we'll see how to use a linear regression model from Scikit-Learn\n",
        "* We'll need to use the original column `'price'`. Apply the logarithmic transformation to this column.\n",
        "* Fit the Ridge regression model on the training data.\n",
        "* This model has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`\n",
        "* Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\n",
        "\n",
        "If there are multiple options, select the smallest `alpha`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebstp7U1wrrX",
        "outputId": "2937e7db-2f0f-4823-d564-c51bc5eee460"
      },
      "source": [
        "y_train = np.log1p(y_train)\n",
        "y_train"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13575    4.605170\n",
              "48476    4.060443\n",
              "44499    4.262680\n",
              "17382    4.875197\n",
              "14638    4.709530\n",
              "           ...   \n",
              "13198    3.931826\n",
              "14583    4.836282\n",
              "6168     5.703782\n",
              "12248    4.189655\n",
              "20523    4.532599\n",
              "Name: price, Length: 29337, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si7HfCftfPNu",
        "outputId": "fad67523-4c18-4381-d932-47b4a5fe8611"
      },
      "source": [
        "dv = DictVectorizer(sparse=False)\n",
        "train_dict = X_train.to_dict(orient='records')\n",
        "X_train_transformed = dv.fit_transform(train_dict)\n",
        "val_dict = X_val.to_dict(orient='records')\n",
        "X_val_transformed = dv.transform(val_dict)\n",
        "\n",
        "scores = []\n",
        "for alpha in [0, 0.01, 0.1, 1, 10]:\n",
        "    model = Ridge(alpha)\n",
        "\n",
        "    model.fit(X_train_transformed, y_train)\n",
        "\n",
        "    scores.append(round(mean_squared_error(model.predict(X_val_transformed), y_val, squared=False), 3))\n",
        "\n",
        "scores"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[268.915, 268.914, 268.914, 268.914, 268.916]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5uOtJb_hcXX"
      },
      "source": [
        "**alpha=0.01** gives the best result."
      ]
    }
  ]
}